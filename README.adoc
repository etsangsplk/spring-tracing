= Spring Tracing with OpenZipkin Brave, Kafka, and Spring Boot
Mario Gray <mgray@pivotal.io>
:Author Initials: MVG
:toc:
:icons:
:numbered:
:website: https://cloud.spring.io/spring-cloud-sleuth/

== Motivation
Trace data is composed of a parent:child tree structure called a Directed Acyclic Graph
(DAG for short).  Where a root node represents the `trace` or overall journey, and each
`span` represents an individual hop along the service route. To illustrate better, I 
have included the original ASCII diagram from the openzipkin github.

```
   Client Tracer                                                  Server Tracer     
┌─────────────────-----─┐                                       ┌────────────────-----──┐
│                       │                                       │                       │
│   TraceContext        │           Http Request Headers        │   TraceContext        │
│ ┌─────────────-----─┐ │          ┌───────────────────┐        │ ┌────────────-----──┐ │
│ │ TraceId           │ │          │ X─B3─TraceId      │        │ │ TraceId           │ │
│ │                   │ │          │                   │        │ │                   │ │
│ │ ParentSpanId      │ │ Extract  │ X─B3─ParentSpanId │ Inject │ │ ParentSpanId      │ │
│ │                   ├─┼─────────>│                   ├────────┼>│                   │ │
│ │ SpanId            │ │          │ X─B3─SpanId       │        │ │ SpanId            │ │
│ │                   │ │          │                   │        │ │                   │ │
│ │ Sampling decision │ │          │ X─B3─Sampled      │        │ │ Sampling decision │ │
│ └──────────-----────┘ │          └───────────────────┘        │ └────────────-----──┘ │
│                       │                                       │                       │
└────────────────-----──┘                                       └───────────────-----───┘
```
                
== Starting up the app
To start, setup a new spring app with the dependencies for Web, Lombok.
Hit this http://start.spring.io/starter.zip?dependencies=web,lombok,h2,jpa&type=maven-project&javaVersion=1.8&baseDir=spring-tracing&packageName=mcp.client&name=spring-tracing[preconfigured start.spring.io] link
to download the base project. Find your favorite editor, and start with standing up a REST 
controller.

.TracingApplication
[source,java]
----
@SpringBootApplication
public class TracingApplication {
	public static void main(String[] args) {
		SpringApplication.run(TracingApplication.class, args);
	}
}

@Configuration
class TracingConfiguration {
	@Bean
	RestTemplate restTemplate() {
		return new RestTemplate(); 
	}
}

@RestController
class TracingRestController {
	private final org.slf4j.Logger log = org.slf4j.LoggerFactory.getLogger(TracingRestController.class);
	private final RestTemplate restTemplate;

	public TracingRestController(RestTemplate rt) {
		this.restTemplate = rt;
	}

	@GetMapping("/backend")
	public String deviceNames(HttpServletRequest req) {
		String clientId = req.getHeader("client-id");
		log.info("clientId=" + clientId);
		return "Hello, " + clientId;
	}

	@GetMapping("/frontend")
	public String callBackend() {
		return restTemplate.getForObject("http://localhost:8080/backend", String.class);
	}
}
----

Then setup the logging properties:

.application.properties
[source,script]
----
logging.pattern.level=%d{ABSOLUTE} [%X{traceId}/%X{spanId}] %-5p [%t] %C{2} - %m%n
logging.level.root=off
logging.level.mcp.cloudtrace=info
spring.application.name=spring-tracing
----

Start the server by running `mvn spring-boot:run` at the command line. And in another
terminal window (or tab), we can validate access to the endpoints.
Try accessing `localhost:8080/frontend` first. Then switch to your server terminal and
observe the logs:

.log_output_notrace
[source,text]
----
...
2018-02-28 18:25:48.531 2018-02-28 18:25:48,531 [/] INFO  [http-nio-8080-exec-2] m.c.ClientRestController - clientId=null
 30145 --- [nio-8080-exec-2] mcp.cloudtrace.ClientRestController      : clientId=null
...
----

== Adding Trace/Span to the service
Notice that `%TraceId/%SpanId` are not being filled in yet.  Lets fix that by
registering an `org.springframework.web.servlet.HandlerInterceptor` that exhibits
trace instrumentation. It will add the span/trace ids for visibility in loggin.
Use the provided `brave.spring.webmvc.TracingHandlerInterceptor` class for tracing
Spring WEB/MVC/REST endpoints. To configure the interceptor, we will need to customize
MVC using a `org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter` 
(or alternately use `WebMvcConfigurer` when using Spring 5.0 or more).

.TraceServiceOnlyConfiguration
[source,java]
----
public class TraceServiceOnlyConfiguration {
    @Bean
    RestTemplate restTemplate() {
        return new RestTemplate();
    }

    @Bean
    Tracing simpleTracing() {
        return Tracing.newBuilder()
                .currentTraceContext((MDCCurrentTraceContext.create()))
                .build();
    }

    @Bean
    HttpTracing httpTracing(Tracing tracing) {
        return HttpTracing.create(tracing);
    }
	
    @Configuration
    public static class WebTracingConfiguration extends WebMvcConfigurerAdapter {
        private final HttpTracing httpTracing;
        public WebTracingConfiguration(HttpTracing tracing) {
            this.httpTracing = tracing;
        }
        @Override
        public void addInterceptors(InterceptorRegistry registry) {
            registry.addInterceptor(TracingHandlerInterceptor.create(httpTracing));
        }
    }
}
----

This interceptor receives an `HttpTracing` object which has the job of not/activating a
new trace, handling any custom trace-scoped needs like propigation and Trace 
Context commuting.

Because we are using SLF4j - that implements it's own version of Managed Diagnostic Context (MDC). 
Thus, `brave.context.slf4j.MDCCurrentTraceContext` is a ready-made Trace Context that 
will expose current trace and span ID's to SLF4j as logging properties with the given
names: `traceId, spanId, parentId`. If you are using log4j2 instead, then a provided
class `brave.context.log4j2.ThreadContextCurrentTraceContext` will do the same for
log4j2's ThreadContext.

Restart your spring-boot application, and then invoke `/frontend` using an http fetching
tool, and observe server logs to confirm that you get `traceId` and `spanId` filled into 
INFO logs.

[source,bash]
----
$ curl -H "client-id: foo" http://localhost:8080/frontend
----

.traced_output
[source,text]
----
2018-02-28 18:49:51.200 2018-02-28 18:49:51,200 [6b5e99f057da5abd/1239a4f2e354ecdf] INFO  [http-nio-8080-exec-2] m.c.ClientRestController - clientId=null
 37142 --- [nio-8080-exec-2] mcp.cloudtrace.ClientRestController      : clientId=null
----


== Tracing across service boundaries
The above example is so far limited in repect to downstream communication. We 
want to enable trace context propagation across service boundaries.  
In this section we'll go into HTTP client-side trace instrumention. 

Clients requests originating from the server will need a trace context. 
The downstream HTTP call will encode using https://github.com/openzipkin/b3-propagation[B3Propagation] it's context as request headers. 
In order to apply this behaviour to our `restTemplate` we must provide -like the server 
setup- an `org.springframework.http.client.ClientHttpRequestInterceptor` to do the 
client-side tracing work.

Additionally, we want to know which client-id was seen during a trace. 
Brave provides the `ExtraFieldPropagation` class to support comprehensive
use of add-on properties.  Although it intrusive as each trace will get laden
with additional data, however it is useful where there are client concerns
to analyze in a trace path.

.TracingClientServiceConfiguration
[source, java]
----
    @Bean
    RestTemplate restTemplate(HttpTracing tracing) {
        return new RestTemplateBuilder()
                .interceptors(TracingClientHttpRequestInterceptor.create(tracing))
                .build();
    }

    @Bean
    Tracing tracing(@Value("${mcp:spring-tracing}") String serviceName) {
        return Tracing
                .newBuilder()
                .sampler(Sampler.ALWAYS_SAMPLE)
                .localServiceName(serviceName)
                .propagationFactory(ExtraFieldPropagation
                        .newFactory(B3Propagation.FACTORY, "client-id"))
                .currentTraceContext(MDCCurrentTraceContext.create())
                .build();
    }
----

.trace_propagated_output
[source,text]
----
2018-03-02 01:13:25.017 2018-03-02 01:13:25,017 [c0d24dc6b7793eb7/738d09ca4e3dd91e]  INFO  [http-nio-8080-exec-2] m.c.ClientRestController - clientId=mario-id
 49687 --- [nio-8080-exec-2] mcp.cloudtrace.ClientRestController      : clientId=mario-id
----

Now, when we call our endpoint, we should see a traceId, spanId, and our `client-id`
as it would have commuted across the entire request chain.

== Shipping traces to zipkin-server
Usually you will want to send your trace logs to an aggregation server for monitoring.
For example, when services do act up you'll be able to pick up which service routes
are affected.

There are a number of ways to get traces into OpenZipkin.  In this seciton, we will dive into 
3 common ways to ship traces to zipkin.

=== Zipkin Direct via HTTP
Spans are created in instrumentation, transported out-of-band, and eventually persisted.
Zipkin uses Reporters `zipkin2.reporter.Reporter` to sends spans (or encoded spans) recorded
by instrumentation out of process. There are a couple of default Reporters that do not send
but can help with testing: `Reporter.NOOP` and `Reporter.CONSOLE`.

In this case, we will configure an (ThreadSafe)`AsyncReporter` that will give us protection from
latency or exceptions when reporting spans out of process. In order to abstract transport
specifics, zipkin includes the `zipkin2.reporter.Sender` component to encode and trasmit 
spans out of process.

.trace_zipkin_bound
[source,java]
----
    @Bean
    Sender sender(@Value("${mcp.zipkin.url}") String zipkinSenderUrl) {
        return OkHttpSender.create(zipkinSenderUrl);
    }

    @Bean
    AsyncReporter<Span> spanReporter(Sender sender) {
        return AsyncReporter.create(sender);
    }

    @Bean
    Tracing tracing(@Value("${mcp:spring-tracing}") String serviceName,
                    AsyncReporter<Span> spanReporter) {
        return Tracing
                .newBuilder()
                .sampler(Sampler.ALWAYS_SAMPLE)
                .localServiceName(serviceName)
                .propagationFactory(ExtraFieldPropagation
                        .newFactory(B3Propagation.FACTORY, "client-id"))
                .currentTraceContext(MDCCurrentTraceContext.create())
                .spanReporter(spanReporter)
                .build();
    }

----

This takes care of getting traces out to zipkin.  Now we can restart our service
make a few endpoint calls, and observe traces locally.

=== Zipkin via Kafka Topic
Support for Kafka topics is possible through the use of `zipkin2.reporter.kafka11.KafkaSender`
sender. We will continue with the same `Tracing` configuration since there is no change there. 

[source,java]
----
    @Bean
    Sender sender(@Value("${mcp.kafka.url}") String kafkaUrl) throws IOException {
        return KafkaSender.create(kafkaUrl);
    }
----

To get OpenZipkin to consume from Kafka, you will need to have a kafka sevice running.
For information on standing up a Kafka server, see https://kafka.apache.org/quickstart[the quickstart] section.
Running the zipkin server is done with the following method:

[source,script]
----
$ KAFKA_ZOOKEEPER=127.0.0.1:2181
$ java -jar /path/kafka-server.jar
----

== RabbitMQ
Another common Sender is the `zipkin2.reporter.amqp.RabbitMQSender` sender. This will ship
JSON encoded spans to a Queue.

Setting up the RabbitMQSender requires a host URL, and the name of the queue which Zipkin-server
is expected to consume.

[source,java]
----
    @Bean
    Sender sender(@Value("${mcp.rabbit.url}") String rabbitmqHostUrl,
                  @Value("${mcp.rabbit.queue}") String zipkinQueue) throws IOException {
        RabbitMQSender sender;

        sender = RabbitMQSender.newBuilder()
                .queue(zipkinQueue)
                .addresses(rabbitmqHostUrl).build();

        return sender;
    }
----

Starting up zipkin server against a rabbitmq server is done with the following:

[source,script]
----
$ export RABBIT_URI=amqp://localhost:5672/
$ java -jar /path/zipkin-server.jar
----