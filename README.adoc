= Spring Tracing with OpenZipkin Brave, Kafka, and Spring Boot
Mario Gray <mgray@pivotal.io>
:Author Initials: MVG
:toc:
:icons:
:numbered:
:website: https://cloud.spring.io/spring-cloud-sleuth/

== Motivation
The more distributed a system the harder it is to debug errors, find latency, and to understand the potentially cascading impact of a bug. External monitoring only tells you the overall response time and number of invocations but doesn't give us a way to understand internal invocations. Structured log entries can be correllated, eventually, to paint a picture of the movement of a request through a system, but structured logs are not easy to query. 



== Trace Primer
Distributed tracing platforms like https://zipkin.io/[Open Zipkin] record trace data.  Trace data is composed of a parent:child tree structure called a Directed Acyclic Graph
(DAG for short).    A root node represents the `trace` or overall journey, and each
`span` represents an individual hop along the service route. To illustrate better, I 
have included an ASCII diagram from https://github.com/openzipkin/zipkin[openzipkin github].

```
   Client Tracer                                                  Server Tracer     
┌─────────────────-----─┐                                       ┌────────────────-----──┐
│                       │                                       │                       │
│   TraceContext        │           Http Request Headers        │   TraceContext        │
│ ┌─────────────-----─┐ │          ┌───────────────────┐        │ ┌────────────-----──┐ │
│ │ TraceId           │ │          │ X─B3─TraceId      │        │ │ TraceId           │ │
│ │                   │ │          │                   │        │ │                   │ │
│ │ ParentSpanId      │ │ Extract  │ X─B3─ParentSpanId │ Inject │ │ ParentSpanId      │ │
│ │                   ├─┼─────────>│                   ├────────┼>│                   │ │
│ │ SpanId            │ │          │ X─B3─SpanId       │        │ │ SpanId            │ │
│ │                   │ │          │                   │        │ │                   │ │
│ │ Sampling decision │ │          │ X─B3─Sampled      │        │ │ Sampling decision │ │
│ └──────────-----────┘ │          └───────────────────┘        │ └────────────-----──┘ │
│                       │                                       │                       │
└────────────────-----──┘                                       └───────────────-----───┘
```
An upstream HTTP call with https://github.com/openzipkin/b3-propagation[B3Propagation]. 
At this time of writing, B3 propagation is supported for HTTP and gRPC. We will utilize both
methods in this example.

== Starting up the app
Generate  a new Spring application with the dependencies for Web and Lombok. Use this link to generate a http://start.spring.io/starter.zip?dependencies=web,lombok,h2,jpa&type=maven-project&javaVersion=1.8&baseDir=spring-tracing&packageName=mcp.client&name=spring-tracing[new project from the Spring Initializr (http://start.spring.io)]. We'll stand up a REST  API with two  endpoints. One endpoint will call the other. We'll use the Spring Framework `RestTemplate`  to make HTTP calls. In this trivial example, we'll have one service call another on the same node, but the principles applies to as many nodes as we'd like. 
This first application will only log trace data at the server ingress point. It demonstrates
the minimal requirements to get started with trace instrumentation.

To start, we need to configure a `brave.Tracing` bean into our application context.
This bean is responsible for providing application-specific trace functionality
within the zipkin trace instrumentation API. It serves as the server-specific configuration
bean for our running node.

Because we are using SLF4j - that implements it's own version of Managed Diagnostic Context (MDC). 
Thus, `brave.context.slf4j.MDCCurrentTraceContext` is a ready-made Trace Context that 
will expose current trace and span ID's to SLF4j as logging properties with the given
names: `traceId, spanId, parentId`. If you are using log4j2 instead, then a provided
class `brave.context.log4j2.ThreadContextCurrentTraceContext` will do the same for
log4j2's `ThreadContext`.

.TracingConfiguration.java
[source,java]
----
@Profile("console")
@Configuration
public class TracingLogOnlyConfiguration {
    @Bean
    Tracing tracing() {
        return Tracing.newBuilder()
                .currentTraceContext((MDCCurrentTraceContext.create()))
                .spanReporter(Reporter.CONSOLE)
                .build();
    }

    @Bean
    HttpTracing httpTracing(Tracing tracing) {
        return HttpTracing.create(tracing);
    }
}
----

This is the REST controller that will let us make requests to our contrived application.

.RestController.java
[source,java]
----
@Profile("web")
@RestController
public class TracingRestController {
    private final RestTemplateBuilder restTemplatebuilder;

    TracingRestController(RestTemplateBuilder restTemplatebuilder) {
        this.restTemplatebuilder = restTemplatebuilder;
    }

    @GetMapping("/backend")
    public String backend() {
        return "Greetings";
    }

    @GetMapping("/frontend")
    public String frontend() {
        return restTemplatebuilder.build()
                .getForObject("http://localhost:8080/backend", String.class);
    }
}
----

The application bootstrap with `@SpringBootApplication` annotation which will make 
execution super simple.

.TracingApplication.java
[source,java]
----
@SpringBootApplication
public class TracingApplication {
    @Autowired
    RestTemplateBuilder restTemplateBuilder;

    public static void main(String[] args) {
        SpringApplication.run(TracingApplication.class, args);
    }
}

----
Configure the logger and give this node a name. 

.application.properties
[source,script]
----
logging.pattern.level=%d{ABSOLUTE} [%X{traceId}/%X{spanId}] %-5p [%t] %C{2} - %m%n
logging.level.root=info
logging.level.mcp.cloudtrace=info

spring.application.name=spring-tracing-http
----

Start the server and invoke the `/frontend` endpoint.

.invoke_log_only
[source,shell]
----
$ mvn spring-boot:run -Dspring.active.profiles=log,web
  ..... logging ....
# In another Terminal:
$ curl -H "client-id: tracing" http://localhost:8080/frontend
Greeting
----

.server_side_console
[source,text]
----
...
2018-03-06 17:51:19.409 2018-03-06 17:51:19,409 [796133ca413bf4f9/796133ca413bf4f9]  INFO  [http-nio-8080-exec-5] m.h.TracingRestController - header client-id =
 12686 --- [nio-8080-exec-5] mcp.http.TracingRestController           : header client-id =
{"traceId":"796133ca413bf4f9","id":"796133ca413bf4f9","kind":"SERVER","name":"get /backend","timestamp":1520387479409105,"duration":1680,"localEndpoint":{"serviceName":"unknown","ipv4":"172.20.10.4"},"remoteEndpoint":{"ipv4":"127.0.0.1","port":60300},"tags":{"http.method":"GET","http.path":"/backend"}}
{"traceId":"4d8b30b495cbf3e5","id":"4d8b30b495cbf3e5","kind":"SERVER","name":"get /frontend","timestamp":1520387479392157,"duration":20559,"localEndpoint":{"serviceName":"unknown","ipv4":"172.20.10.4"},"remoteEndpoint":{"ipv6":"::1","port":60299},"tags":{"http.method":"GET","http.path":"/frontend"}}
...
----

Notice that `%TraceId/%SpanId` are the same? Thats because each commponent in the trace
path is not receiving a trace context from the previous hop. Lets fix that by registering an implementation of `org.springframework.web.servlet.HandlerInterceptor` that exhibits Zipkin trace instrumentation to SpringMVC.

To instrument SpringMVC endpoints, we will need to configure an instance of the `brave.spring.webmvc.TracingHandlerInterceptor` class. To configure the interceptor, we will need to register a `org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter` that gives us hooks into SpringMVC's `InterceptorRegistry` (or alternately use `WebMvcConfigurer` when using Spring 5.0 or more).

.WebMvcConfiguration
[source,java]
----
@Profile("web")
@Configuration
public class WebMVCTracingConfiguration extends WebMvcConfigurerAdapter {
    private final HttpTracing httpTracing;

    public WebMVCTracingConfiguration(HttpTracing httpTracing) {
        this.httpTracing = httpTracing;
    }

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(TracingHandlerInterceptor.create(httpTracing));
    }
}
----

This interceptor receives an `HttpTracing` object which gives our `Tracing` bean
the functionality to apply HTTP client/server tracing.

== Tracing the Client
In order to apply Trace Context propagation to our `restTemplate` we must provide -like the server 
setup- an `org.springframework.http.client.ClientHttpRequestInterceptor` to do the 
client-side tracing work. We'll use the `RestTemplateCustomizer` callback interface
to modify the RestTemplate bean we defined earlier.

.TraceClientConfiguration
[source,java]
----
@Profile("web")
@Configuration
class WebClientTracingConfiguration {

    @Bean
    public RestTemplateCustomizer restTemplateCustomizer(HttpTracing tracing) {
        return restTemplate -> restTemplate
                .setInterceptors(Arrays
                        .asList(TracingClientHttpRequestInterceptor.create(tracing)
                ));
    }
}
----

.trace_propagated_output
[source,text]
----
2018-03-02 01:13:25.017 2018-03-02 01:13:25,017 [c0d24dc6b7793eb7/738d09ca4e3dd91e]  INFO  [http-nio-8080-exec-2] m.c.ClientRestController - clientId=mario-id
 49687 --- [nio-8080-exec-2] mcp.cloudtrace.ClientRestController      : clientId=mario-id
----

Now, when we call our endpoint, we should see a traceId, spanId, and our `client-id`
as it would have commuted across the entire request chain.

== Shipping traces to zipkin-server
Usually you will want to send your trace logs to an aggregation server for monitoring.
For example, when services do act up you'll be able to pick up which service routes
are affected.

There are a number of ways to get traces into OpenZipkin.  In this seciton, we will dive into 
3 common ways to ship traces to zipkin.

=== Zipkin Direct via HTTP
Spans are created in instrumentation, transported out-of-band, and eventually persisted.
Zipkin uses Reporters `zipkin2.reporter.Reporter` to sends spans (or encoded spans) recorded
by instrumentation out of process. There are a couple of default Reporters that do not send
but can help with testing: `Reporter.NOOP` and `Reporter.CONSOLE`.

In this case, we will configure an (ThreadSafe)`AsyncReporter` that will give us protection from
latency or exceptions when reporting spans out of process. In order to abstract transport
specifics, zipkin includes the `zipkin2.reporter.Sender` component to encode and trasmit 
spans out of process.

.trace_zipkin_bound
[source,java]
----
    @Bean
    Sender sender(@Value("${mcp.zipkin.url}") String zipkinSenderUrl) {
        return OkHttpSender.create(zipkinSenderUrl);
    }

    @Bean
    AsyncReporter<Span> spanReporter(Sender sender) {
        return AsyncReporter.create(sender);
    }

    @Bean
    Tracing tracing(@Value("${mcp:spring-tracing}") String serviceName,
                    AsyncReporter<Span> spanReporter) {
        return Tracing
                .newBuilder()
                .sampler(Sampler.ALWAYS_SAMPLE)
                .localServiceName(serviceName)
                .propagationFactory(ExtraFieldPropagation
                        .newFactory(B3Propagation.FACTORY, "client-id"))
                .currentTraceContext(MDCCurrentTraceContext.create())
                .spanReporter(spanReporter)
                .build();
    }

----

This takes care of getting traces out to zipkin.  Now we can restart our service
make a few endpoint calls, and observe traces locally.

=== Zipkin via Kafka Topic
Support for Kafka topics is possible through the use of `zipkin2.reporter.kafka11.KafkaSender`
sender. We will continue with the same `Tracing` configuration since there is no change there. 

[source,java]
----
    @Bean
    Sender sender(@Value("${mcp.kafka.url}") String kafkaUrl) throws IOException {
        return KafkaSender.create(kafkaUrl);
    }
----

To get OpenZipkin to consume from Kafka, you will need to have a kafka sevice running.
For information on standing up a Kafka server, see https://kafka.apache.org/quickstart[the quickstart] section.
Running the zipkin server is done with the following method:

[source,script]
----
$ KAFKA_ZOOKEEPER=127.0.0.1:2181
$ java -jar /path/kafka-server.jar
----

== RabbitMQ
Another common Sender is the `zipkin2.reporter.amqp.RabbitMQSender` sender. This will ship
JSON encoded spans to a Queue.

Setting up the RabbitMQSender requires a host URL, and the name of the queue which Zipkin-server
is expected to consume.

[source,java]
----
    @Bean
    Sender sender(@Value("${mcp.rabbit.url}") String rabbitmqHostUrl,
                  @Value("${mcp.rabbit.queue}") String zipkinQueue) throws IOException {
        RabbitMQSender sender;

        sender = RabbitMQSender.newBuilder()
                .queue(zipkinQueue)
                .addresses(rabbitmqHostUrl).build();

        return sender;
    }
----

Starting up zipkin server against a rabbitmq server is done with the following:

[source,script]
----
$ export RABBIT_URI=amqp://localhost:5672/
$ java -jar /path/zipkin-server.jar
----
